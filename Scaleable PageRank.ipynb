{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ashlitaylor/ashlitaylor.github.io/master/images/pagerank.jpg\" height=\"600\" width=\"400\">\n",
    "<header> \n",
    "    <h2 align=\"center\"> Scalable Single-Machine PageRank on 70M edge graph </h2>\n",
    "    <h6 align=\"center\"> PageRank algorithm implementation </h6>\n",
    "</header>\n",
    "\n",
    "### Background\n",
    "PageRank, named after Google co-founder Larry Page, is an algorithm that measures webpage importance. According to Google:\n",
    ">\"PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website is. The underlying assumption is that more important websites are likely to receive more links from other websites\"\n",
    "\n",
    "The PageRank algorithm I implemented can scale to graph datasets with as many as billions of edges. Ordinarily, running such an algorithm on large datasets would require the use of computer clusters (e.g. Spark, Hadoop), however I implemented this algorithm using my computer's virtual memory. \n",
    "\n",
    "#### Virtual Memory\n",
    "The main idea is to place the dataset in your computer’s (unlimited) virtual memory, as it is often too big to fit in the RAM. When running algorithms on the dataset (e.g., PageRank), the operating system will automatically decide when to load the necessary data (subset of whole dataset) into RAM. See <a href = \"http://poloclub.gatech.edu/mmap/\">here</a> for more details on research on virtual memory mapping. \n",
    "\n",
    "The mapping for this algorithm is done using Python's <a href = \"https://docs.python.org/3/library/mmap.html\">mmap</a> and <a href = \"https://docs.python.org/2/library/struct.html\">struct</a> modules, and I used PyPy to expedite the packing and unpacking functionality of Python. \n",
    "\n",
    "I used this PageRank algorithm on the <a href = \"https://snap.stanford.edu/data/soc-LiveJournal1.html\">LiveJournal</a> graph, which contains almost 70 million edges. The algorithm outputs the 10 nodes with the highest PageRank scores. I generated output using 10 iterations, 25 iterations, and 50 iterations. \n",
    "\n",
    "#### Motivation\n",
    "The motivation for this work was an assignment that explored how to use my computer’s virtual memory to implement the PageRank algorithm that will scale to graph datasets with as many as billions of edges using a single computer (e.g. my laptop). \n",
    "\n",
    "Below is code for the PageRank algorithm (power iteration).\n",
    "\n",
    "Here, the binary index_file contains the mapping of each node's ID to its degree.\n",
    "The node IDs range from 0 to max_node_id.\n",
    "Hence, the index_file contains (max_node_id + 1) pairs of values,\n",
    "each of which is of 'int' C type in little endian byte order.\n",
    "The index_file is memory-mapped into the index_map object.\n",
    "\n",
    "The binary edge_file contains the edges in the (source ID, target ID) format.\n",
    "Hence, the edge_file contains edge_count pairs of values,\n",
    "each of which is of 'int' C type in big endian byte order.\n",
    "The edge_file is memory-mapped into the edge_map object.\n",
    "\n",
    "My task was to determine the correct parameters needed to\n",
    "(1) initialize the memory-mapped objects (index_map and edge_map),\n",
    "(2) unpack the source and target IDs from the edge_map, and\n",
    "(3) upack the source ID and source degree from the index_map.\n",
    "\n",
    "This code assumes that the node IDs start from 0 and are contiguous up to max_node_id.\n",
    "This algorithm returns the same scores as popular graph analysis libraries like NetworkX.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(index_file, edge_file, max_node_id, edge_count, damping_factor=0.85, iterations=10):\n",
    "    index_map = mmap.mmap(\n",
    "        index_file.fileno(),\n",
    "        length= (max_node_id+1)*8,  \n",
    "        access=mmap.ACCESS_READ)\n",
    "\n",
    "    edge_map = mmap.mmap(\n",
    "        edge_file.fileno(),\n",
    "        length= edge_count * 8,  \n",
    "        access=mmap.ACCESS_READ)\n",
    "\n",
    "    scores = [1.0 / (max_node_id + 1)] * (max_node_id + 1)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for it in range(iterations):\n",
    "        new_scores = [0.0] * (max_node_id + 1)\n",
    "\n",
    "        for i in range(edge_count):\n",
    "            source, target = unpack(\n",
    "                '>ii',  \n",
    "                edge_map[i * 8: i * 8 + 8])  \n",
    "\n",
    "            source_degree = unpack(\n",
    "                '<ii',  \n",
    "                index_map[source * 8: source * 8 + 8])[1]  \n",
    "\n",
    "            new_scores[target] += damping_factor * scores[source] / source_degree\n",
    "\n",
    "        min_pr = (1 - damping_factor) / (max_node_id + 1)\n",
    "        new_scores = [min_pr + item for item in new_scores]\n",
    "        scores = new_scores\n",
    "\n",
    "        print (\"Completed {0}/{1} iterations. {2} seconds elapsed.\" \\\n",
    "            .format(it + 1, iterations, time.time() - start_time))\n",
    "\n",
    "    print ()\n",
    "\n",
    "    return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
